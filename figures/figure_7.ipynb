{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import torchvision.models as models\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize = 5000\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(digits, oodDigit):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),    \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    transformC = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),    \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transformC)\n",
    "    \n",
    "    train = torch.tensor([1 if data.targets[i] in digits  else 0 for i in range(len(data))])\n",
    "    data = torch.utils.data.Subset(data, train.nonzero())\n",
    "\n",
    "    testIn = datasets.CIFAR10(root='./data', train=False, download=True, transform=transformC)\n",
    "    \n",
    "    test = torch.tensor([1 if testIn.targets[i] in digits  else 0 for i in range(len(testIn))])\n",
    "    testIn = torch.utils.data.Subset(testIn, test.nonzero())\n",
    "\n",
    "    testOut = datasets.CIFAR10(root='./data', train=False, download=True, transform=transformC)\n",
    "    \n",
    "    test = torch.tensor([1 if testOut.targets[i] in [oodDigit]  else 0 for i in range(len(testOut))])\n",
    "    testOut = torch.utils.data.Subset(testOut, test.nonzero())\n",
    "    \n",
    "    OOD = datasets.MNIST(root = './data', train = False, transform = transform, download = True)\n",
    "    OOD2 = datasets.CIFAR100(root='./data', train=False, download=True, transform=transformC)\n",
    "    OOD3 = datasets.SVHN(root = './data', split='test', transform = transformC, download = True)\n",
    "\n",
    "    data, _ = torch.utils.data.random_split(data, [trainSize, len(data)-trainSize])\n",
    "    testIn, _ = torch.utils.data.random_split(testIn, [300, len(testIn)-300])\n",
    "    testOut, _ = torch.utils.data.random_split(testOut, [300, len(testOut)-300])\n",
    "    OOD, _ = torch.utils.data.random_split(OOD, [300, len(OOD)-300])\n",
    "    OOD2, _ = torch.utils.data.random_split(OOD2, [300, len(OOD2)-300])\n",
    "    OOD3, _ = torch.utils.data.random_split(OOD3, [300, len(OOD3)-300])\n",
    "\n",
    "    return data, testIn, testOut, OOD, OOD2, OOD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_latent_vectors(model, train_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    latent_vectors = {}\n",
    "    for cnt, x in enumerate(train_loader):\n",
    "        x = x[0].to(device) # Move the minibatch to gpu\n",
    "        features = model(x)\n",
    "\n",
    "        for i in range(len(features)):\n",
    "            if cnt == 0:\n",
    "                latent_vectors[str(i)] = []    \n",
    "\n",
    "            latent_vectors[str(i)].append(features[i].mean(dim=(2,3)))\n",
    "\n",
    "    # Concatenate all vectors\n",
    "    for i in range(len(features)):\n",
    "        latent_vectors[str(i)] = torch.cat(latent_vectors[str(i)]).cpu().numpy()\n",
    "\n",
    "    return latent_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/ORippler/gaussian-ad-mvtec\n",
    "class ResNet_features(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        resnet: nn.Module,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = resnet.conv1\n",
    "\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x0 = self.maxpool(x)\n",
    "\n",
    "        result = []\n",
    "        x1 = self.layer1(x0)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "\n",
    "        for i in [0, 1, 2, 3, 4]:\n",
    "            result.append(locals()[\"x\" + str(i)])\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data, testIn, testOut, OOD, OOD2, OOD3, digits):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    network = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "    network = ResNet_features(network)\n",
    "\n",
    "    network = nn.DataParallel(network)\n",
    "\n",
    "    network.to(device)\n",
    "    network.eval()\n",
    "\n",
    "    trainLoader = torch.utils.data.DataLoader(data, batch_size=bs, shuffle=False, num_workers=4)\n",
    "    trainFeatures = get_latent_vectors(network, trainLoader, device)\n",
    "\n",
    "    inLoader = torch.utils.data.DataLoader(testIn, batch_size=bs, shuffle=False, num_workers=4)\n",
    "    inFeatures = get_latent_vectors(network, inLoader, device)\n",
    "\n",
    "    outLoader = torch.utils.data.DataLoader(testOut, batch_size=bs, shuffle=False, num_workers=4)\n",
    "    outFeatures = get_latent_vectors(network, outLoader, device)\n",
    "\n",
    "    OODLoader = torch.utils.data.DataLoader(OOD, batch_size=bs, shuffle=False, num_workers=4)\n",
    "    oodFeatures = get_latent_vectors(network, OODLoader, device)\n",
    "    \n",
    "    OOD2Loader = torch.utils.data.DataLoader(OOD2, batch_size=bs, shuffle=False, num_workers=4)\n",
    "    ood2Features = get_latent_vectors(network, OOD2Loader, device)\n",
    "    \n",
    "    OOD3Loader = torch.utils.data.DataLoader(OOD3, batch_size=bs, shuffle=False, num_workers=4)\n",
    "    ood3Features = get_latent_vectors(network, OOD3Loader, device)\n",
    "    \n",
    "    return trainFeatures, inFeatures, outFeatures, oodFeatures, ood2Features, ood3Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maha(train, points):\n",
    "    train = np.array(train)\n",
    "    mean = np.mean(train, axis=0)\n",
    "\n",
    "    LW = LedoitWolf().fit(train)\n",
    "    covI = np.linalg.inv(LW.covariance_)\n",
    "    \n",
    "    points = (points - mean)[:, None]\n",
    "    dists = covI @ points.transpose(0, 2, 1)\n",
    "    dists = points @ dists\n",
    "    dists = np.sqrt(dists[:, 0, 0])    \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(trainFeatures, features):\n",
    "    scores = np.zeros(features[str(0)].shape[0])\n",
    "\n",
    "    for layer in range(5):\n",
    "        dists = maha(trainFeatures[str(layer)], features[str(layer)])\n",
    "        scores += dists\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_knn(trainFeatures, features):\n",
    "    model = NearestNeighbors(n_neighbors=2)\n",
    "\n",
    "    model.fit(trainFeatures['4'])\n",
    "    dists = np.mean(model.kneighbors(features['4'])[0], axis=1)\n",
    "        \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(scoresIn, scoresOut):\n",
    "    groundTruthIn = np.array([1 for i in range(len(scoresIn))])\n",
    "    groundTruthOut = np.array([-1 for i in range(len(scoresOut))])\n",
    "\n",
    "    groundTruth = np.append(groundTruthIn, groundTruthOut)\n",
    "\n",
    "    scores = np.append(scoresIn, scoresOut)\n",
    "\n",
    "    auroc = roc_auc_score(groundTruth, scores)\n",
    "    \n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahascores = {}\n",
    "dn2scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lars/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lars/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lars/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lars/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lars/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lars/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lars/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lars/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lars/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "digits = []\n",
    "outscores = []\n",
    "oodscores = []\n",
    "ood2scores = []\n",
    "ood3scores = []\n",
    "\n",
    "outscores_knn = []\n",
    "oodscores_knn = []\n",
    "ood2scores_knn = []\n",
    "ood3scores_knn = []\n",
    "\n",
    "for i in range(9):\n",
    "    digits.append(1+i)\n",
    "    \n",
    "    data, testIn, testOut, OOD, OOD2, OOD3 = get_data(digits, 0)\n",
    "    trainFeatures, inFeatures, outFeatures, oodFeatures, ood2Features, ood3Features = \\\n",
    "        get_features(data, testIn, testOut, OOD, OOD2, OOD3, digits)\n",
    "\n",
    "    inScores = get_scores(trainFeatures, inFeatures)\n",
    "    outScores = get_scores(trainFeatures, outFeatures)\n",
    "    oodScores = get_scores(trainFeatures, oodFeatures)\n",
    "    ood2Scores = get_scores(trainFeatures, ood2Features)\n",
    "    ood3Scores = get_scores(trainFeatures, ood3Features)\n",
    "\n",
    "    outscores.append(auc(-1*inScores, -1*outScores))\n",
    "    oodscores.append(auc(-1*inScores, -1*oodScores))\n",
    "    ood2scores.append(auc(-1*inScores, -1*ood2Scores))\n",
    "    ood3scores.append(auc(-1*inScores, -1*ood3Scores))\n",
    "    \n",
    "    inScores = get_scores_knn(trainFeatures, inFeatures)\n",
    "    outScores = get_scores_knn(trainFeatures, outFeatures)\n",
    "    oodScores = get_scores_knn(trainFeatures, oodFeatures)\n",
    "    ood2Scores = get_scores_knn(trainFeatures, ood2Features)\n",
    "    ood3Scores = get_scores_knn(trainFeatures, ood3Features)\n",
    "\n",
    "    outscores_knn.append(auc(-1*inScores, -1*outScores))\n",
    "    oodscores_knn.append(auc(-1*inScores, -1*oodScores))\n",
    "    ood2scores_knn.append(auc(-1*inScores, -1*ood2Scores))\n",
    "    ood3scores_knn.append(auc(-1*inScores, -1*ood3Scores))\n",
    "\n",
    "mahascores['held'] = outscores\n",
    "mahascores['ood'] = oodscores\n",
    "mahascores['ood2'] = ood2scores\n",
    "mahascores['ood3'] = ood3scores\n",
    "\n",
    "dn2scores['held'] = outscores_knn\n",
    "dn2scores['ood'] = oodscores_knn\n",
    "dn2scores['ood2'] = ood2scores_knn\n",
    "dn2scores['ood3'] = ood3scores_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "plt.figure()\n",
    "labels = ['MahaAD', 'DN2', 'MSCL']\n",
    "colors = ['b', 'purple', 'orange']\n",
    "# for idx, method in enumerate([mahascores, dn2scores, msclscores]):\n",
    "for idx, method in enumerate([mahascores, dn2scores]):\n",
    "    plt.plot(np.arange(len(method['ood'])) + 1, method['ood'], colors[idx], linestyle='-.', linewidth=4.5, alpha=0.6)\n",
    "    plt.plot(np.arange(len(method['ood3'])) + 1, method['ood3'], colors[idx], linewidth=4.5, label=labels[idx], alpha=0.6)\n",
    "\n",
    "plot_lines = []\n",
    "l, = plt.plot([-1], '-', color='black')\n",
    "l2, = plt.plot([-1], '-.', color='black')\n",
    "plot_lines.append([l, l2])\n",
    "legend1 = plt.legend(plot_lines[0], [\"SVHN\", 'MNIST'], loc=4)\n",
    "plt.gca().add_artist(legend1)\n",
    "\n",
    "plt.xlabel('Number of classes in')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.ylim(0.4, 1.03)\n",
    "plt.xlim(0.7, 9.3)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "labels = ['MahaAD', 'DN2', 'MSCL']\n",
    "colors = ['b', 'purple', 'orange']\n",
    "for idx, method in enumerate([mahascores, dn2scores]):\n",
    "# for idx, method in enumerate([mahascores, dn2scores, msclscores]):\n",
    "    plt.plot(np.arange(len(method['held'])) + 1, method['held'], colors[idx], linestyle='-.', label=labels[idx], linewidth=4.5, alpha=0.6)\n",
    "    plt.plot(np.arange(len(method['ood2'])) + 1, method['ood2'], colors[idx], linewidth=4.5, alpha=0.6)\n",
    "    \n",
    "plot_lines = []\n",
    "l, = plt.plot([-1], '-', color='black')\n",
    "l2, = plt.plot([-1], '-.', color='black')\n",
    "plot_lines.append([l, l2])\n",
    "legend1 = plt.legend(plot_lines[0], ['CIFAR100', \"Held out class\"], loc=4)\n",
    "plt.gca().add_artist(legend1)\n",
    "\n",
    "plt.xlabel('Number of classes in')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.ylim(0.4, 1.03)\n",
    "plt.xlim(0.7, 9.3)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
