{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "import torch\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "trainSize = 5000\n",
    "testSize = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),    \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    data = datasets.CIFAR10(root='../../data', train=True, download=True, transform=transform)\n",
    "    testIn = datasets.CIFAR10(root='../../data', train=False, download=True, transform=transform)\n",
    "    OOD = datasets.SVHN(root = '../../data', split='test', transform = transform, download = True)\n",
    "    \n",
    "    print(len(data), len(testIn), len(OOD))\n",
    "\n",
    "    data, _ = torch.utils.data.random_split(data, [trainSize, len(data)-trainSize])\n",
    "    testIn, _ = torch.utils.data.random_split(testIn, [testSize, len(testIn)-testSize])\n",
    "    OOD, _ = torch.utils.data.random_split(OOD, [testSize, len(OOD)-testSize])\n",
    "    print(len(data), len(testIn), len(OOD))\n",
    "    \n",
    "    return data, testIn, OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_latent_vectors(model, train_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    latent_vectors = {}\n",
    "    for cnt, x in enumerate(train_loader):\n",
    "        x = x[0].to(device)\n",
    "\n",
    "        features = model(x)\n",
    "        for i in range(len(features)):\n",
    "            if cnt == 0:\n",
    "                latent_vectors[str(i)] = []    \n",
    "\n",
    "            latent_vectors[str(i)].append(features[i].mean(dim=(2,3)))\n",
    "\n",
    "    # Concatenate all vectors\n",
    "    for i in range(len(features)):\n",
    "        latent_vectors[str(i)] = torch.cat(latent_vectors[str(i)]).cpu().numpy()\n",
    "    \n",
    "    return latent_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/ORippler/gaussian-ad-mvtec\n",
    "class ResNet_features(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        resnet: nn.Module,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = resnet.conv1\n",
    "\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x0 = self.maxpool(x)\n",
    "\n",
    "        result = []\n",
    "        x1 = self.layer1(x0)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "\n",
    "        for i in [0, 1, 2, 3, 4]:\n",
    "            result.append(locals()[\"x\" + str(i)])\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data, testIn, OOD):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    network = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "    network = ResNet_features(network)\n",
    "\n",
    "    network = nn.DataParallel(network)\n",
    "\n",
    "    network.to(device)\n",
    "    network.eval()\n",
    "\n",
    "    trainLoader = torch.utils.data.DataLoader(data, batch_size=bs, shuffle=False, num_workers=4)\n",
    "    trainFeatures = get_latent_vectors(network, trainLoader, device)\n",
    "\n",
    "    inLoader = torch.utils.data.DataLoader(testIn, batch_size=bs, shuffle=False, num_workers=4)\n",
    "    inFeatures = get_latent_vectors(network, inLoader, device)\n",
    "\n",
    "    OODLoader = torch.utils.data.DataLoader(OOD, batch_size=bs, shuffle=False, num_workers=4)\n",
    "    oodFeatures = get_latent_vectors(network, OODLoader, device)\n",
    "\n",
    "    return trainFeatures, inFeatures, oodFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maha(train, points):\n",
    "    train = np.array(train)\n",
    "    mean = np.mean(train, axis=0)\n",
    "\n",
    "    LW = LedoitWolf().fit(train)\n",
    "    covI = np.linalg.inv(LW.covariance_)\n",
    "    \n",
    "    points = (points - mean)[:, None]\n",
    "    dists = covI @ points.transpose(0, 2, 1)\n",
    "    dists = points @ dists\n",
    "    dists = np.sqrt(dists[:, 0, 0])    \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(scoresIn, scoresOut):\n",
    "    groundTruthIn = np.array([1 for i in range(len(scoresIn))])\n",
    "    groundTruthOut = np.array([-1 for i in range(len(scoresOut))])\n",
    "\n",
    "    groundTruth = np.append(groundTruthIn, groundTruthOut)\n",
    "\n",
    "    scores = np.append(scoresIn, scoresOut)\n",
    "\n",
    "    auroc = roc_auc_score(groundTruth, -1 * scores)\n",
    "    \n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../../data/test_32x32.mat\n",
      "50000 10000 26032\n",
      "5000 300 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lars/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "/home/lars/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c120c1b69847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestIn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOOD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrainFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moodFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestIn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOOD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-982b0bb8f124>\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(data, testIn, OOD)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrainLoader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrainFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_latent_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minLoader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestIn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b57957b8ad8f>\u001b[0m in \u001b[0;36mget_latent_vectors\u001b[0;34m(model, train_loader, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlatent_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oodscores = []\n",
    "\n",
    "trainTransformed = {}\n",
    "inTransformed = {}\n",
    "oodTransformed = {}\n",
    "variances = {}\n",
    "\n",
    "for i in range(1):\n",
    "    data, testIn, OOD = get_data()\n",
    "    trainFeatures, inFeatures, oodFeatures = get_features(data, testIn, OOD)\n",
    "    \n",
    "    pca = PCA()\n",
    "    \n",
    "    for layer in range(5):\n",
    "        trainTransformed[str(layer)] = pca.fit_transform(trainFeatures[str(layer)])\n",
    "\n",
    "        inTransformed[str(layer)] = pca.transform(inFeatures[str(layer)])\n",
    "        oodTransformed[str(layer)] = pca.transform(oodFeatures[str(layer)])\n",
    "        \n",
    "        variances[str(layer)] = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "labels = ['SVHN']\n",
    "\n",
    "ticks = np.arange(0.5, 0.95, 0.01)\n",
    "aucs = []\n",
    "for i in ticks:\n",
    "    scoresIn = np.zeros(inTransformed[str(layer)].shape[0])\n",
    "    scoresOut = np.zeros(inTransformed[str(layer)].shape[0])\n",
    "\n",
    "    for layer in range(5):\n",
    "        comps = np.where(np.cumsum(variances[str(layer)]) > i)[0][0]\n",
    "        scoresIn += maha(trainTransformed[str(layer)][:, :comps], inTransformed[str(layer)][:, :comps])\n",
    "        scoresOut += maha(trainTransformed[str(layer)][:, :comps], oodTransformed[str(layer)][:, :comps])\n",
    "\n",
    "    aucs.append(auc(scoresIn, scoresOut))\n",
    "plt.plot(ticks, aucs, label=labels[0], linewidth=4.5)\n",
    "\n",
    "plt.ylim(0.6, 1.03)\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Fraction of variance explained by components used')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "labels = ['SVHN']\n",
    "\n",
    "ticks = np.arange(0.95, 0.999, 0.005)\n",
    "aucs = []\n",
    "for i in ticks:\n",
    "    scoresIn = np.zeros(inTransformed[str(layer)].shape[0])\n",
    "    scoresOut = np.zeros(inTransformed[str(layer)].shape[0])\n",
    "\n",
    "    for layer in range(5):\n",
    "        comps = np.where(np.cumsum(variances[str(layer)]) > i)[0][0]\n",
    "\n",
    "        scoresIn += maha(trainTransformed[str(layer)][:, comps:], inTransformed[str(layer)][:, comps:])\n",
    "        scoresOut += maha(trainTransformed[str(layer)][:, comps:], oodTransformed[str(layer)][:, comps:])\n",
    "\n",
    "    aucs.append(auc(scoresIn, scoresOut))\n",
    "plt.plot(1 - ticks, aucs, label=labels[0], linewidth=4.5)\n",
    "    \n",
    "plt.ylim(0.65, 1.03)\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Fraction of variance explained by components used')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
